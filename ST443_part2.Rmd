---
title: "Estimation of Graphical Models Using Lasso-Related Approaches"
author: "Bowen Deng"
date: "08/11/2019"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r package, include=FALSE}
source("functions.R") #import own functions
```

## 1 Generate Samples
***

```{r}
set.seed(666)
# number of random variables
p <- 50
# number of samples generated
n <- 1000
# delta to construct Theta Matrix
prob <- 0.1

data <- generate(p, n, prob)
```

## 2 Estimation
***
### 2.1 Node-wise Lasso Approach
```{r}
pred.nodewise <- predict.nodewise(data$X, lambda = 0.05)
table(pred.nodewise$E_1[,3], data$E_true[,3]) # compare estimation E_1 and true set E_true
table(pred.nodewise$E_2[,3], data$E_true[,3]) # compare estimation E_2 and true set E_true
```

### 2.2 Graphical Lasso Approach
```{r}
pred.glasso <- predict.glasso(data$X, lambda = 0.05)
table(pred.glasso$E[,3], data$E_true[,3]) # compare estimation E_3 and true set E_true
```

## 3 ROC Curve and Overall Performance
***
To produce a ROC curve, a grid of lambda is needed.
```{r}
len_grid <- 50
grid <- 10 ^ seq(0.5,-2.5, length = len_grid)
```

Run nodewise lasso over the grid. For this data, It took more than 10 secs.
```{r}
start = Sys.time()
perf.nodewise <- performance.nodewise.grid(data$X, data$E_true, grid)
end = Sys.time()
end-start
```

Run graphical lasso over the grid. For this data, It took less than 1 secs. Glasso is much faster.
```{r}
start = Sys.time()
perf.glasso <- performance.glasso.grid(data$X, data$E_true, grid)
end = Sys.time()
end-start
```

```{r, fig.height = 3, fig.width = 9, fig.align = "center"}
# png(filename = "../plot/roc.png", width = 1200, height = 450, res=200)

par(mfrow=c(1,3))
plot.roc(perf.nodewise$tpr_1, perf.nodewise$fpr_1, "ROC of Approach 1")
plot.roc(perf.nodewise$tpr_2, perf.nodewise$fpr_2, "ROC of Approach 2")
plot.roc(perf.glasso$tpr, perf.glasso$fpr, "ROC of Graphical Lasso")

# dev.off()
```

```{r, results='hold'}
cat("AUC for method 1: ", perf.nodewise$auc_1, "\n")
cat("AUC for method 2: ", perf.nodewise$auc_2, "\n")
cat("AUC for method 3: ", perf.glasso$auc, "\n")
```

## 4 Optimal Tuning Parameters
***
Plot error rate $(FN+FP)/total$ against lambda, we can find the optimal lambda generate minimum error rate.
```{r}
# png(filename = "../plot/error.png", width = 1200, height = 900, res=200)

plot(log10(grid), perf.nodewise$error_1, type="l"
     , xlab = "log10(lambda)", ylab = "error rate"
     , col=2
     )
lines(log10(grid), perf.nodewise$error_2, col=3)
lines(log10(grid), perf.glasso$error, col=4)
legend("bottomright",legend=c("approach 1","approach 2", "approach 3"), col=c(2,3,4), pch="-")

lambda_1 <- grid[which.min(perf.nodewise$error_1)]
lambda_2 <- grid[which.min(perf.nodewise$error_2)]
lambda_3 <- grid[which.min(perf.glasso$error)]

abline(v=log10(lambda_1), col=2, lty=2)
abline(v=log10(lambda_2), col=3, lty=4)
abline(v=log10(lambda_3), col=4, lty=2)

# dev.off()
```

Inspired by K-fold cross validaion, K error rates are generated on each lambda using different folds of data. Then one-standard-deviation rule can be applied.
```{r}
set.seed(666)

len_grid <- 50
grid <- 10 ^ seq(-0.7, -1.3, length = len_grid)

K =10
folds = sample(rep(1:K, length = n))

Error_1 <- c()
Error_2 <- c()
Error_3 <- c()
for (k in 1:K){
  perf.nodewise <- performance.nodewise.grid(data$X[folds!=k,], data$E_true, grid)
  perf.glasso <- performance.glasso.grid(data$X[folds!=k,], data$E_true, grid)

  Error_1 <- rbind(Error_1, perf.nodewise$error_1)
  Error_2 <- rbind(Error_2, perf.nodewise$error_2)
  Error_3 <- rbind(Error_3, perf.glasso$error)
}
```

```{r}
png(filename = "../plot/errorcv.png", width = 1200, height = 900, res=200)

plot.cv.error(Error_1, grid, col=2, ylim=c(0, 0.014)
              , xlab=expression(paste("log(",lambda,")")), ylab="mean error rate")
par(new=T)
plot.cv.error(Error_2, grid, col=3, ylim=c(0, 0.014)
              , xlab=expression(paste("log(",lambda,")")), ylab="mean error rate")
par(new=T)
plot.cv.error(Error_3, grid, col=4, ylim=c(0, 0.014)
              , xlab=expression(paste("log(",lambda,")")), ylab="mean error rate")
legend("topright",legend=c("node-wise 1","node-wise 2", "graphical"), col=c(2,3,4), pch="-", cex = 0.75)

dev.off()
```

```{r}
png(filename = "../plot/errorcvzoom.png", width = 1200, height = 300, res=130)

par(mfrow=c(1,3))
plot.cv.error(Error_1, grid, zoom = 2
              , xlab=expression(paste("log(",lambda,")")), ylab="mean error rate")
title(main = "node-wise 1")
plot.cv.error(Error_2, grid, zoom = 2
              , xlab=expression(paste("log(",lambda,")")), ylab="mean error rate")
title(main = "node-wise 2")
plot.cv.error(Error_3, grid, zoom = 6
              , xlab=expression(paste("log(",lambda,")")), ylab="mean error rate")
title(main = "graphical")

dev.off()
```

```{r}
10^-1.045
10^-1.05
10^-0.96
```





## 5 Mean and Standard Error of Different Approaches
***
```{r}
# it takes about 10 min to run this code chunk
set.seed(666)
p <- 50
n <- 1000
prob <- 0.1
delta <- 3
len_grid <- 50
grid <- 10 ^ seq(0.5,-2.5, length = len_grid)

auc_1 <- c()
auc_2 <- c()
auc_3 <- c()
Error_1 <- c()
Error_2 <- c()
Error_3 <- c()
t = 1
while (t<=50){
  data <- generate(p, n, prob)
  while ( sum(data$E_true[,3])==0 ){ data <- generate(p, n, prob) }
  perf.nodewise <- performance.nodewise.grid(data$X, data$E_true, grid)
  perf.glasso <- performance.glasso.grid(data$X, data$E_true, grid)

  auc_1 <- append(auc_1, perf.nodewise$auc_1)
  auc_2 <- append(auc_2, perf.nodewise$auc_2)
  auc_3 <- append(auc_3, perf.glasso$auc)
  Error_1 <- rbind(Error_1, perf.nodewise$error_1)
  Error_2 <- rbind(Error_2, perf.nodewise$error_2)
  Error_3 <- rbind(Error_3, perf.glasso$error)

  t <- t+1
}
```

```{r, results="hold"}
cat("AUC of Method 1\n   mean:           ", mean(auc_1), "\n   standard error: ", sd(auc_1), "\n\n")
cat("AUC of Method 2\n   mean:           ", mean(auc_2), "\n   standard error: ", sd(auc_2), "\n\n")
cat("AUC of Method 3\n   mean:           ", mean(auc_3), "\n   standard error: ", sd(auc_3), "\n\n")

min_error_1 <- apply(Error_1, 1, min)
min_error_2 <- apply(Error_2, 1, min)
min_error_3 <- apply(Error_3, 1, min)
cat("Minimum Error Rate of Method 1\n   mean:           ", mean(min_error_1), "\n   standard error: ", sd(min_error_1), "\n\n")
cat("Minimum Error Rate of Method 2\n   mean:           ", mean(min_error_2), "\n   standard error: ", sd(min_error_2), "\n\n")
cat("Minimum Error Rate of Method 3\n   mean:           ", mean(min_error_3), "\n   standard error: ", sd(min_error_3), "\n\n")
```

```{r, fig.height = 5, fig.width = 7, fig.align = "center"}
# png(filename = "../plot/boxplot.png", width = 1200, height = 800, res=180)

par(mfrow=c(1,2))
boxplot(auc_1, auc_2, auc_3)
title("AUC")
boxplot(min_error_1, min_error_2, min_error_3)
title("Minumun Error Rate")

# dev.off()
```

## 6 Different simulation settings
```{r}
set.seed(666)

p <- 50
prob <- 0.1
len_grid <- 20
grid <- 10 ^ seq(0.5,-2.5, length = len_grid)

ns <- c(seq(10,130,length = 6), seq(200,1100,length = 5))
auc_n_1 <- c()
auc_n_2 <- c()
auc_n_3 <- c()
for (n in ns){
  n <- round(n)
  print(n)
  data <- generate(p, n, prob)
  while ( sum(data$E_true[,3])==0 ){ data <- generate(p, n, prob) }
  perf.nodewise <- performance.nodewise.grid(data$X, data$E_true, grid)
  perf.glasso <- performance.glasso.grid(data$X, data$E_true, grid)
  auc_n_1 <- append(auc_n_1, perf.nodewise$auc_1)
  auc_n_2 <- append(auc_n_2, perf.nodewise$auc_2)
  auc_n_3 <- append(auc_n_3, perf.glasso$auc)
}
```

```{r}
set.seed(666)
n <- 500
p <- 50
len_grid <- 20
grid <- 10 ^ seq(0.5,-2.5, length = len_grid)

probs <- 10 ^ seq(-4,-0.3, length = 10)
auc_prob_1 <- c()
auc_prob_2 <- c()
auc_prob_3 <- c()
for (prob in probs){
  print(prob)
  data <- generate(p, n, prob)
  while ( sum(data$E_true[,3])==0 ){ data <- generate(p, n, prob) }
  perf.nodewise <- performance.nodewise.grid(data$X, data$E_true, grid)
  perf.glasso <- performance.glasso.grid(data$X, data$E_true, grid)

  auc_prob_1 <- append(auc_prob_1, perf.nodewise$auc_1)
  auc_prob_2 <- append(auc_prob_2, perf.nodewise$auc_2)
  auc_prob_3 <- append(auc_prob_3, perf.glasso$auc)
}
```

plot AUC against n.
```{r}
# png(filename = "../plot/auc_n.png", width = 1200, height = 800, res=180)

plot(ns, auc_n_1, "l", col=1, lty=1
     , xlab = "n", ylab = "AUC"
     )
lines(ns, auc_n_2, col=2, lty=4)
lines(ns, auc_n_3, col=3, lty=4)
title("p=50, prob=0.1")
legend("bottomright",legend=c("approach 1","approach 2", "approach 3"), col=c(1,2,3), pch="-", cex = 1)

# dev.off()
```

plot AUC against prob.
```{r}
# png(filename = "../plot/auc_prob.png", width = 1200, height = 800, res=180)

plot(log10(probs), auc_prob_1, "l", col=1, lty=1
     , ylim = c(0.7, 0.995)
     , xlab = "log10(prob)", ylab = "AUC"
     )
lines(log10(probs), auc_prob_2, col=2, lty=1)
lines(log10(probs), auc_prob_3, col=3, lty=1)
title("p=50, n=500")
legend("bottomleft",legend=c("approach 1","approach 2", "approach 3"), col=c(1,2,3), pch="-", cex = 1)

# dev.off()
```
