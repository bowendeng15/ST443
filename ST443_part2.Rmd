---
title: "Estimation of Graphical Models Using Lasso-Related Approaches"
author: "Bowen Deng"
date: "08/11/2019"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r package, include=FALSE}
library(MASS) #mvrnorm
library(glmnet) #lasso
```

## 1 Generate Samples
***

```{r}
set.seed(19970530)

# number of random variables
p = 20 
# number of samples generated
n = 1000
# delta to construct Theta Matrix
delta = 2 

Theta <- matrix(0,p,p) + delta*diag(p)
for (i in 2:p){
  for (j in 1:(i-1)){
    Theta[i,j] = 0.5*rbinom(1, 1, 0.1)
    Theta[j,i] = Theta[i,j]
  }
}
Theta = Theta/delta

Sigma = solve(Theta) # Sigma is inverse of Theta

X = mvrnorm(n=n, mu=rep(0, p), Sigma=Sigma)

head(Sigma[,1:6])
```

```{r}
# construct set E as a matrix
# column 1: Integer, index i
# column 2: Integer, index j
# column 3: Boolean, 1 for included, 0 for not included 
E_true <- matrix(nrow=0, ncol=3)
for (i in 1:(p-1)){
  for (j in (i+1):p){
    if (Sigma[i,j]){
      E_true <- rbind(E_true, c(i,j,1))
    }
    else{
      E_true <- rbind(E_true, c(i,j,0))
    }
  }
}
head(E_true)
```

## 2 Estimation 
***
### 2.1 Node-wise Lasso Approach
```{r}
# estimate beta
Beta <- matrix(nrow=0, ncol=p)
for (j in 1:p){
  cv.lasso <- cv.glmnet(X[,-j], X[,j])
  beta_j <- coef(cv.lasso)[2:p]
  Beta <- rbind(Beta
                , append(beta_j, NA, after=j-1) # NA just a placeholder, meaningless
                ) 
}

# hence get E_1 and E_2
E_1 <- matrix(nrow=0, ncol=3)
E_2 <- matrix(nrow=0, ncol=3)
for (i in 1:(p-1)){
  for (j in (i+1):p){
    if (Beta[i,j]){
      E_1 <- rbind(E_1, c(i,j,1))
    }
    else{
      E_1 <- rbind(E_1, c(i,j,0))
    }
    if (Beta[i,j] && Beta[j,i]){
      E_2 <- rbind(E_2, c(i,j,1))
    }
    else{
      E_2 <- rbind(E_2, c(i,j,0))
    }
  }
}

# confusion matrix
table(E_1[,3], E_true[,3])
table(E_2[,3], E_true[,3])
```

### 2.2 Graphical Lasso Approach
```{r}
# TODO
```

## 3 ROC Curve and Overall Performance 
***
### 3.1 Node-wise Lasso Approach

```{r Beta}
len_grid <- 100
grid <- 10 ^ seq(1,-4, length = len_grid)

Beta <- array(dim = c(p, p, len_grid))

for (j in 1:p){
  lasso <- glmnet(X[,-j], X[,j], lambda = grid)
  Coef_j <- as.matrix( coef(lasso)[2:p,] ) # drop the 1st element, which is coef of Intercept
  # insert a row as placeholder. e.g. for Xj, the jth row of Coef Matrix should be placeholder
  Beta_j <- matrix(nrow = p, ncol = len_grid)
  if (j==1){
    Beta_j[2:p,] <- Coef_j
  } else if (j==p) {
    Beta_j[1:p-1,] <- Coef_j
  } else {
    Beta_j[1:(j-1),] <- Coef_j[1:(j-1),]
    Beta_j[(j+1):p,] <- Coef_j[j:(p-1),]
  }
  # combine the Beta Matrix
  Beta[j,,] <- Beta_j
}
```

```{r TPR FPR}
tpr_1 <- c()
fpr_1 <- c()
tpr_2 <- c()
fpr_2 <- c()

# loop for different lambda
for (k in 1:len_grid){
  
  # for a certain lambda, Beta[,,k] is the Beta Matrix
  # construct set E_1 and E_2 in Matrix form
  E_1 <- matrix(nrow=0, ncol=3)
  E_2 <- matrix(nrow=0, ncol=3)
  for (i in 1:(p-1)){
    for (j in (i+1):p){
      if (Beta[i,j,k]){
        E_1 <- rbind(E_1, c(i,j,1))
      }
      else{
        E_1 <- rbind(E_1, c(i,j,0))
      }
      if (Beta[i,j,k] && Beta[j,i,k]){
        E_2 <- rbind(E_2, c(i,j,1))
      }
      else{
        E_2 <- rbind(E_2, c(i,j,0))
      }
    }
  }
  
  # derive TPR and FPR from the confusion matrix
  Tab_1 <- table(E_1[,3], E_true[,3])
  if (!(0 %in% rownames(Tab_1))){
    Tab_1 <- rbind(c(0,0), Tab_1) # in case all predictions are 1
  }
  if (!(1 %in% rownames(Tab_1))){
    Tab_1 <- rbind(Tab_1, c(0,0)) # in case all predictions are 0
  }
  tpr_1 <- append(tpr_1, Tab_1[2,2]/(sum(Tab_1[,2])) )
  fpr_1 <- append(fpr_1, Tab_1[2,1]/(sum(Tab_1[,1])) ) 
  
  Tab_2 <- table(E_2[,3], E_true[,3])
  if (!(0 %in% rownames(Tab_2))){
    Tab_2 <- rbind(c(0,0), Tab_2)
  }
  if (!(1 %in% rownames(Tab_2))){
    Tab_2 <- rbind(Tab_2, c(0,0))
  }
  tpr_2 <- append(tpr_2, Tab_2[2,2]/(sum(Tab_2[,2])) )
  fpr_2 <- append(fpr_2, Tab_2[2,1]/(sum(Tab_2[,1])) )
}
```

```{r, fig.height = 5, fig.width = 10, fig.align = "center"}
plot_roc <- function(TPR, FPR, title){
  plot(FPR, TPR, "l"
       , xlab="FPR", ylab="TPR"
       , xlim=c(0,1), ylim=c(0,1)
       , xaxs="i", yaxs="i"
       )
  abline(a=0, b=1, col="red")
  title(main = title)
}

par(mfrow=c(1,2))
plot_roc(tpr_1, fpr_1, "ROC Curve of Method 1")
plot_roc(tpr_2, fpr_2, "ROC Curve of Method 2")
```


```{r, results='hold'}
auc <- function(TPR, FPR){
  dFPR <- c(diff(FPR), 0)
  dTPR <- c(diff(TPR), 0)
  return( sum(TPR * dFPR) + sum(dTPR * dFPR)/2 ) 
}

cat("AUC for method 1: ", auc(tpr_1, fpr_1), "\n")
cat("AUC for method 2: ", auc(tpr_2, fpr_2), "\n")
```

### 3.2 Graphical Lasso Approach
```{r}
# TODO
```

## 4 Optimal Tuning Parameters
***
```{r}
# TODO
```

## 5 Mean and Standard Error of Different Approaches
***
```{r}
# TODO
```